{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_module import Preprocessing,FeatureSelection # type: ignore\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,classification_report\n",
    "from scipy import stats\n",
    "\n",
    "from pretty_confusion_matrix import pp_matrix_from_data\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialze classes, constansts and variables\n",
    "COLORS = sns.color_palette('bright')[0:5]\n",
    "DATASET = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
    "preprocessor = Preprocessing(DATASET)\n",
    "\n",
    "#check for missing value and repair it if present\n",
    "missing_data_removed_Dataset = preprocessor.check_missing_value()\n",
    "\n",
    "#show descriptive statistics of the dataset, including mean median skewness and kurtosis\n",
    "preprocessor.descriptives(missing_data_removed_Dataset)\n",
    "\n",
    "# exploratory data analysis using visualizations\n",
    "#countplot distribution of death event\n",
    "sns.countplot(x='DEATH_EVENT', data=missing_data_removed_Dataset)\n",
    "plt.show()\n",
    "\n",
    "#boxplot distribution Death Event in respect to diabetes and age\n",
    "sns.boxplot(x='diabetes', y='age', hue='DEATH_EVENT', data=missing_data_removed_Dataset)\n",
    "plt.show()\n",
    "\n",
    "sns.catplot(x='DEATH_EVENT', y='ejection_fraction', data=missing_data_removed_Dataset, kind='box')\n",
    "plt.show()\n",
    "\n",
    "plt.pie(missing_data_removed_Dataset['diabetes'].value_counts(), colors=COLORS, labels=['No Diabetes', 'Diabetes'], autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification I\n",
    "#split the dataset into training and test set\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(missing_data_removed_Dataset.drop('DEATH_EVENT', axis=1), missing_data_removed_Dataset['DEATH_EVENT'], test_size=0.2, random_state=42)\n",
    "\n",
    "#Fitting Maching Learning Models\n",
    "## Support Vector Machine\n",
    "Support_vector_machine = SVC(C = .1, kernel='linear', random_state=42)\n",
    "Support_vector_machine.fit(X_Train, Y_Train)\n",
    "\n",
    "## Random Forest Classifier\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_classifier.fit(X_Train, Y_Train)\n",
    "\n",
    "## Naive Bayes\n",
    "Naive_Bayes = GaussianNB()\n",
    "Naive_Bayes.fit(X_Train, Y_Train)\n",
    "\n",
    "## Logistic Regression\n",
    "Logistic_Regression = LogisticRegression(random_state=42)\n",
    "Logistic_Regression.fit(X_Train, Y_Train)\n",
    "\n",
    "\n",
    "##Knearst Neighbors\n",
    "Knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "Knn_model.fit(X_Train, Y_Train)\n",
    "\n",
    "## Multi Layer Perceptron\n",
    "Multi_layer_perceptron = MLPClassifier(hidden_layer_sizes=(6,5),\n",
    "                    verbose=False,\n",
    "                    learning_rate_init=0.01)\n",
    "Multi_layer_perceptron.fit(X_Train, Y_Train)\n",
    "\n",
    "print('All Models have been fitted successfully')\n",
    "\n",
    "\n",
    "#Evaluating models\n",
    "predicted_naives_bayes_classifier = Naive_Bayes.predict(X_Test)\n",
    "predicted_support_vector_machine = Support_vector_machine.predict(X_Test)\n",
    "predicted_random_forest_classifier = random_forest_classifier.predict(X_Test)\n",
    "predicted_logistic_regression = Logistic_Regression.predict(X_Test)\n",
    "predicted_multi_layer_perceptron = Multi_layer_perceptron.predict(X_Test)\n",
    "predicted_knn_model = Knn_model.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting confusion matrix for all models\n",
    "pp_matrix_from_data(Y_Test, predicted_naives_bayes_classifier) # type: ignore\n",
    "pp_matrix_from_data(Y_Test, predicted_support_vector_machine) # type: ignore\n",
    "pp_matrix_from_data(Y_Test, predicted_logistic_regression) # type: ignore\n",
    "pp_matrix_from_data(Y_Test, predicted_random_forest_classifier) # type: ignore\n",
    "pp_matrix_from_data(Y_Test, predicted_multi_layer_perceptron) # type: ignore\n",
    "pp_matrix_from_data(Y_Test, predicted_knn_model) # type: ignore\n",
    "\n",
    "#showing performance for all models in terms of accuracy,presicion, recall and f1 score by using a classification report\n",
    "print(\"Classification-Report-Naive-Bayes \\n\",classification_report(Y_Test, predicted_naives_bayes_classifier))\n",
    "print(\"Classification-Report-SVM \\n\",classification_report(Y_Test, predicted_support_vector_machine))\n",
    "print(\"Classification-Report-Logistic-Regression \\n\",classification_report(Y_Test, predicted_logistic_regression))\n",
    "print(\"Classification-Report-Random-Forest-Classifier \\n\",classification_report(Y_Test, predicted_random_forest_classifier, zero_division=0)) # type: ignore\n",
    "print(\"Classification-Report-MLP \\n\",classification_report(Y_Test, predicted_multi_layer_perceptron, zero_division=0)) # type: ignore\n",
    "print(\"Classification-Report-KNN \\n\",classification_report(Y_Test, predicted_knn_model)) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                    #Classification II\n",
    "#checking class imbalance problem\n",
    "sns.countplot(x='DEATH_EVENT', data=missing_data_removed_Dataset).set(title='Imbalance Dataset')\n",
    "plt.show()\n",
    "                                    #Fixing class imbalance problem\n",
    "######sampling technique (Oversampling)\n",
    "#divinding to classes\n",
    "death_event_true = missing_data_removed_Dataset[missing_data_removed_Dataset['DEATH_EVENT'] == 1]\n",
    "death_event_false = missing_data_removed_Dataset[missing_data_removed_Dataset['DEATH_EVENT'] == 0]\n",
    "# print(death_event_false)\n",
    "\n",
    "#random oversampling\n",
    "class_death_event_true_increase = death_event_true.sample(death_event_false.shape[0], replace=True)\n",
    "fixed_imbalance_dataset = pd.concat([death_event_false, class_death_event_true_increase], axis=0)\n",
    "sns.countplot(x='DEATH_EVENT', data=fixed_imbalance_dataset).set(title='Fixed Imbalance Dataset')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training on Fixed Imbalance Dataset\n",
    "#split the dataset into training and test set\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(fixed_imbalance_dataset.drop('DEATH_EVENT', axis=1), fixed_imbalance_dataset['DEATH_EVENT'], test_size=0.2, random_state=42)\n",
    "\n",
    "#Fitting Maching Learning Models\n",
    "## Support Vector Machine\n",
    "Support_vector_machine = SVC(C = .1, kernel='linear', random_state=42)\n",
    "Support_vector_machine.fit(X_Train, Y_Train)\n",
    "\n",
    "## Random Forest Classifier\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_classifier.fit(X_Train, Y_Train)\n",
    "\n",
    "## Naive Bayes\n",
    "Naive_Bayes = GaussianNB()\n",
    "Naive_Bayes.fit(X_Train, Y_Train)\n",
    "\n",
    "## Logistic Regression\n",
    "Logistic_Regression = LogisticRegression(random_state=42)\n",
    "Logistic_Regression.fit(X_Train, Y_Train)\n",
    "\n",
    "\n",
    "##Knearst Neighbors\n",
    "Knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "Knn_model.fit(X_Train, Y_Train)\n",
    "\n",
    "## Multi Layer Perceptron\n",
    "Multi_layer_perceptron = MLPClassifier(hidden_layer_sizes=(6,5),\n",
    "                    verbose=False,\n",
    "                    learning_rate_init=0.01)\n",
    "Multi_layer_perceptron.fit(X_Train, Y_Train)\n",
    "\n",
    "print('All Models have been fitted successfully')\n",
    "\n",
    "\n",
    "#Evaluating models\n",
    "predicted_naives_bayes_classifier = Naive_Bayes.predict(X_Test)\n",
    "predicted_support_vector_machine = Support_vector_machine.predict(X_Test)\n",
    "predicted_random_forest_classifier = random_forest_classifier.predict(X_Test)\n",
    "predicted_logistic_regression = Logistic_Regression.predict(X_Test)\n",
    "predicted_multi_layer_perceptron = Multi_layer_perceptron.predict(X_Test)\n",
    "predicted_knn_model = Knn_model.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting confusion matrix for all models\n",
    "pp_matrix_from_data(Y_Test, predicted_naives_bayes_classifier) # type: ignore\n",
    "pp_matrix_from_data(Y_Test, predicted_support_vector_machine) # type: ignore\n",
    "pp_matrix_from_data(Y_Test, predicted_logistic_regression) # type: ignore\n",
    "pp_matrix_from_data(Y_Test, predicted_random_forest_classifier) # type: ignore\n",
    "pp_matrix_from_data(Y_Test, predicted_multi_layer_perceptron) # type: ignore\n",
    "pp_matrix_from_data(Y_Test, predicted_knn_model) # type: ignore\n",
    "\n",
    "#showing performance for all models in terms of accuracy,presicion, recall and f1 score by using a classification report\n",
    "print(\"Classification-Report-Naive-Bayes \\n\",classification_report(Y_Test, predicted_naives_bayes_classifier))\n",
    "print(\"Classification-Report-SVM \\n\",classification_report(Y_Test, predicted_support_vector_machine))\n",
    "print(\"Classification-Report-Logistic-Regression \\n\",classification_report(Y_Test, predicted_logistic_regression))\n",
    "print(\"Classification-Report-Random-Forest-Classifier \\n\",classification_report(Y_Test, predicted_random_forest_classifier, zero_division=0)) # type: ignore\n",
    "print(\"Classification-Report-MLP \\n\",classification_report(Y_Test, predicted_multi_layer_perceptron, zero_division=0)) # type: ignore\n",
    "print(\"Classification-Report-KNN \\n\",classification_report(Y_Test, predicted_knn_model)) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE SELECTION\n",
    "#hypothesis for the testing\n",
    "print(\" Hypothesis for the Testing \\n\\n \\\n",
    "H₀ (Null Hypothesis) — that the 2 categorical variables being compared are independent of each other. \\n \\\n",
    "H₁ (Alternate Hypothesis) — that the 2 categorical variables being compared are dependent on each other. \\\n",
    "\")\n",
    "\n",
    "p_value_scores_chi_square = {}\n",
    "p_value_scores_mann_whitney = {}\n",
    "# loop through all features and check if they are independent or not\n",
    "for i,j in enumerate(missing_data_removed_Dataset.columns):\n",
    "    chi_square_args = pd.crosstab(missing_data_removed_Dataset[j], missing_data_removed_Dataset['DEATH_EVENT']).values\n",
    "    stat, p_value_mann_whit = stats.mannwhitneyu(missing_data_removed_Dataset[j], missing_data_removed_Dataset['DEATH_EVENT'])\n",
    "    _, p_value, _, _ = stats.chi2_contingency(chi_square_args)\n",
    "\n",
    "    p_value_scores_chi_square[f'{j} Vs Death event'] = p_value\n",
    "    p_value_scores_mann_whitney[f'{j} Vs Death event'] = p_value_mann_whit\n",
    "print(p_value_scores_chi_square)\n",
    "print(p_value_scores_mann_whitney)\n",
    "\n",
    "#ranking the features based on p_value\n",
    "def rank_function(x):\n",
    "    print(x)\n",
    "    return x < 0.05\n",
    "\n",
    "sorted(p_value_scores_chi_square.items(),key=lambda x: x[1] < 0.05, reverse=True)\n",
    "sorted(p_value_scores_chi_square.items(),key=lambda x: x[1] < 0.05, reverse=True)\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fedf8c85ff2f8c19347a51a3840e3309ccc16fc14237907ac70fb35b569aef71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
